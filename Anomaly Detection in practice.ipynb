{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection in Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import time\n",
    "np.random.seed(42)\n",
    "\n",
    "# import the outlier detection toolkit\n",
    "# install it with \n",
    "# ! pip install --upgrade pyod \n",
    "import pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 95371, 1: 1183})\n"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "content = open('../../../../../Desktop/kdd-cup-1999-data/kddcup.names', 'r').readlines()\n",
    "\n",
    "buf, *features = content\n",
    "\n",
    "features_types_dict = {f.split(':')[0]: f.split(':')[1][1:-2] for f in features}\n",
    "features = list(features_types_dict.keys())\n",
    "\n",
    "content = open('../../../../../Desktop/kdd-cup-1999-data/training_attack_types', 'r').readlines()\n",
    "\n",
    "buf = content[:-1]\n",
    "\n",
    "attack_types_dict = {line.split()[0]: line.split()[1] for line in buf}\n",
    "attack_types_dict['normal'] = 'normal'\n",
    "\n",
    "# Load data into df\n",
    "data_file = '../../../../../Desktop/kdd-cup-1999-data/kddcup.data.gz'\n",
    "\n",
    "data = pd.read_csv(data_file, \n",
    "                      header=None, \n",
    "                      names=features + ['label'])\n",
    "data['label'] = [i[:-1] for i in data['label'].values]\n",
    "\n",
    "# select 'smtp' as service\n",
    "\n",
    "ds = data[data.service == 'smtp'].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "label_dict = {\n",
    "    'normal': 0,\n",
    "    'neptune': 1,\n",
    "    'satan': 1,\n",
    "    'nmap':1,\n",
    "    'portsweep': 1,\n",
    "    'ipsweep': 1\n",
    "}\n",
    "\n",
    "ds['label'] = [label_dict[item] for item in ds['label']]\n",
    "\n",
    "X, y = ds.drop('label', axis = 1), ds.label\n",
    "\n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py_36/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "numerical_columns_selector = make_column_selector(dtype_exclude=object)\n",
    "num_features = numerical_columns_selector(X)\n",
    "\n",
    "categorical_columns_selector = make_column_selector(dtype_include=object)\n",
    "cat_features = categorical_columns_selector(X)\n",
    "\n",
    "\n",
    "\n",
    "for feat in num_features:\n",
    "        scaler = StandardScaler()\n",
    "        X[feat] = scaler.fit_transform(np.array(X[feat]).reshape(-1, 1))\n",
    "for feat in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        X[feat] = encoder.fit_transform(np.array(X[feat]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64691, 41) (64691,)\n",
      "F-1: 0.9922077922077923\n",
      "ROC_AUC: 0.9973322989135613\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# summarize the shape of the training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# fit the model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1 = f1_score(y_test, yhat)\n",
    "auc = roc_auc_score(y_test, yhat)\n",
    "print('F-1: {}\\nROC_AUC: {}'.format(f1, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram-based Outlier Detection (HBOS)\n",
    "*(from pyod)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 58222 outliers, kept 6469 inliers\n",
      "F-1: 0.9883570504527813\n",
      "ROC_AUC: 0.9972846480987324\n",
      "Time (s): 2.154905080795288\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "contamination = 0.1\n",
    "hbos = HBOS(contamination=contamination)\n",
    "\n",
    "# fit the data to HBOS\n",
    "start = time.time()\n",
    "hbos.fit(X_train)\n",
    "end = time.time()\n",
    "y_hat = hbos.predict(X_train)\n",
    "\n",
    "# filter out predictions values = 0\n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != 0\n",
    "\n",
    "out_hbos, in_hbos = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_hbos, in_hbos))\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_hbos = f1_score(y_test, y_pred)\n",
    "auc_hbos = roc_auc_score(y_test, y_pred)\n",
    "time_hbos = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_hbos, auc_hbos, time_hbos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density-Based Spatial Clustering of Applications with Noise(DBSCAN)\n",
    "*(from scikit-learn)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 13 outliers, kept 64678 inliers\n",
      "F-1: 0.9934810951760104\n",
      "ROC_AUC: 0.996061982790114\n",
      "Time (s): 169.66550707817078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.1, min_samples=2, metric='cosine')\n",
    "\n",
    "# fit the data to DBSCAN\n",
    "start = time.time()\n",
    "y_hat = dbscan.fit_predict(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# filter out predictions values = -1 \n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != -1\n",
    "\n",
    "out_dbscan, in_dbscan = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_dbscan, in_dbscan))\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_dbscan = f1_score(y_test, y_pred)\n",
    "auc_dbscan = roc_auc_score(y_test, y_pred)\n",
    "time_dbscan = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_dbscan, auc_dbscan, time_dbscan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Class Support Vector Machine (OCSVM)\n",
    "*(from scikit-learn)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 32355 outliers, kept 32336 inliers\n",
      "F-1: 0.896797153024911\n",
      "ROC_AUC: 0.9909009279996188\n",
      "Time (s): 536.9208903312683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM as OCSVM\n",
    "\n",
    "ocsvm = OCSVM(gamma='auto', kernel='linear')\n",
    "\n",
    "\n",
    "# fit the data to OCSVM\n",
    "start = time.time()\n",
    "y_hat = ocsvm.fit_predict(X_train, y_train)\n",
    "end = time.time()\n",
    "# filter out predictions values = -1 \n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != -1\n",
    "\n",
    "out_ocsvm, in_ocsvm = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_ocsvm, in_ocsvm))\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_ocsvm = f1_score(y_test, y_pred)\n",
    "auc_ocsvm = roc_auc_score(y_test, y_pred)\n",
    "time_ocsvm = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_ocsvm, auc_ocsvm, time_ocsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IsolationForest Outlier Detector \n",
    "*(from pyod also on scikit-learn)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 58222 outliers, kept 6469 inliers\n",
      "F-1: 0.9869451697127937\n",
      "ROC_AUC: 0.9921239655802281\n",
      "Time (s): 7.078562021255493\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "random_state = np.random.RandomState(42)\n",
    "contamination = 0.1\n",
    "iso = IForest(contamination=contamination, random_state=random_state)\n",
    "\n",
    "# fit the data to IF\n",
    "start = time.time()\n",
    "iso.fit(X_train)\n",
    "end = time.time()\n",
    "\n",
    "y_hat = iso.predict(X_train)\n",
    "\n",
    "# filter out predictions values = 0\n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != 0\n",
    "\n",
    "out_iso, in_iso = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_iso, in_iso))\n",
    "\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "\n",
    "f1_iso = f1_score(y_test, y_pred)\n",
    "auc_iso = roc_auc_score(y_test, y_pred)\n",
    "time_iso = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_iso, auc_iso, time_iso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor (LOF) \n",
    "*(from pyod also on scikit-learn)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 58903 outliers, kept 5788 inliers\n",
      "F-1: 0.9750982961992136\n",
      "ROC_AUC: 0.9842638147653991\n",
      "Time (s): 90.03914904594421\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.lof import LOF\n",
    "\n",
    "contamination = 0.1\n",
    "lof = LOF(n_neighbors=20, algorithm='auto', leaf_size=30, metric='minkowski', contamination = contamination)\n",
    "\n",
    "# fit the data to LOF\n",
    "start = time.time()\n",
    "lof.fit(X_train)\n",
    "end = time.time()\n",
    "\n",
    "y_hat = lof.predict(X_train)\n",
    "\n",
    "# filter out predictions values = 0\n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != 0\n",
    "\n",
    "out_lof, in_lof = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_lof, in_lof))\n",
    "\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_lof = f1_score(y_test, y_pred)\n",
    "auc_lof = roc_auc_score(y_test, y_pred)\n",
    "time_lof = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_lof, auc_lof, time_lof))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Based Local Outlier Factor (CBLOF) \n",
    "*(from pyod)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 58222 outliers, kept 6469 inliers\n",
      "F-1: 0.9869451697127937\n",
      "ROC_AUC: 0.9921239655802281\n",
      "Time (s): 2.391855001449585\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "\n",
    "random_state = np.random.RandomState(42)\n",
    "contamination = 0.1\n",
    "cblof = CBLOF(contamination=contamination, check_estimator=False, random_state=random_state)\n",
    "\n",
    "# fit the data to CBLOF\n",
    "start = time.time()\n",
    "cblof.fit(X_train)\n",
    "end = time.time()\n",
    "y_hat = cblof.predict(X_train)\n",
    "\n",
    "# filter out predictions values = 0\n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != 0\n",
    "\n",
    "out_cblof, in_cblof = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_cblof, in_cblof))\n",
    "\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_cblof = f1_score(y_test, y_pred)\n",
    "auc_cblof = roc_auc_score(y_test, y_pred)\n",
    "time_cblof = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_cblof, auc_cblof, time_cblof))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOD\n",
    "*(from pyod)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 58034 outliers, kept 6657 inliers\n",
      "F-1: 0.9869451697127937\n",
      "ROC_AUC: 0.9921239655802281\n",
      "Time (s): 112.96911573410034\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.abod import ABOD\n",
    "\n",
    "contamination = 0.1\n",
    "abod = ABOD(contamination=contamination)\n",
    "\n",
    "# fit the data to ABOD\n",
    "start = time.time()\n",
    "abod.fit(X_train)\n",
    "end = time.time()\n",
    "\n",
    "y_hat = abod.predict(X_train)\n",
    "\n",
    "# filter out predictions values = 0\n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != 0\n",
    "\n",
    "out_abod, in_abod = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_abod, in_abod))\n",
    "\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_abod = f1_score(y_test, y_pred)\n",
    "auc_abod = roc_auc_score(y_test, y_pred)\n",
    "time_abod = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_abod, auc_abod, time_abod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feaure Bagging \n",
    "*(from pyod)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 59093 outliers, kept 5598 inliers\n",
      "F-1: 0.9736147757255936\n",
      "ROC_AUC: 0.9803893319752851\n",
      "Time (s): 930.2121160030365\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "\n",
    "random_state = np.random.RandomState(42)\n",
    "contamination = 0.1\n",
    "fbd = FeatureBagging(LOF(n_neighbors=20),contamination=contamination,\n",
    "                    check_estimator=False,random_state=random_state)\n",
    "\n",
    "# fit the data to FB\n",
    "start = time.time()\n",
    "fbd.fit(X_train)\n",
    "end = time.time()\n",
    "\n",
    "y_hat = fbd.predict(X_train)\n",
    "\n",
    "# filter out predictions values = 0\n",
    "# as they are considered as anomalies\n",
    "mask = y_hat != 0\n",
    "\n",
    "out_fb, in_fb = Counter(mask)[0],Counter(mask)[1]\n",
    "\n",
    "print('Removed {} outliers, kept {} inliers'.format(out_fb, in_fb))\n",
    "\n",
    "\n",
    "X_masked, y_masked = X_train[mask], y_train[mask]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_masked, y_masked)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "f1_fb = f1_score(y_test, y_pred)\n",
    "auc_fb = roc_auc_score(y_test, y_pred)\n",
    "time_fb = end-start\n",
    "print('F-1: {}\\nROC_AUC: {}\\nTime (s): {}'.format(f1_fb, auc_fb, time_fb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Detector', 'Outliers', 'Inliers', 'Time (s)', 'F1', 'ROC_AUC']\n",
    "\n",
    "detectors = ['None', 'OCSVM', 'ABOD', 'CBLOF', 'DBSCAN', 'FB', 'IF', 'HBOS', 'LOF']\n",
    "\n",
    "aucs = [auc, auc_ocsvm, auc_abod, auc_cblof, auc_dbscan, auc_fb, auc_iso, auc_hbos, auc_lof]\n",
    "\n",
    "f1s = [f1, f1_ocsvm, f1_abod, f1_cblof, f1_dbscan, f1_fb, f1_iso, f1_hbos, f1_lof]\n",
    "\n",
    "times = [np.NaN, time_ocsvm, time_abod, time_cblof, time_dbscan, time_fb, time_iso, time_hbos, time_lof]\n",
    "\n",
    "inliers = [np.NaN, in_ocsvm, in_abod, in_cblof, in_dbscan, in_fb, in_iso, in_hbos, in_lof]\n",
    "\n",
    "outliers = [np.NaN, out_ocsvm, out_abod, out_cblof, out_dbscan, out_fb, out_iso, out_hbos, out_lof]\n",
    "\n",
    "df = pd.DataFrame(columns=cols)\n",
    "df.Detector = detectors\n",
    "df.Outliers = outliers\n",
    "df.Inliers = inliers\n",
    "df.F1 = f1s\n",
    "df.ROC_AUC = aucs\n",
    "df['Time (s)'] = times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detector</th>\n",
       "      <th>Outliers</th>\n",
       "      <th>Inliers</th>\n",
       "      <th>Time (s)</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.997332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCSVM</td>\n",
       "      <td>32355.0</td>\n",
       "      <td>32336.0</td>\n",
       "      <td>536.920890</td>\n",
       "      <td>0.896797</td>\n",
       "      <td>0.990901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABOD</td>\n",
       "      <td>58034.0</td>\n",
       "      <td>6657.0</td>\n",
       "      <td>112.969116</td>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.992124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBLOF</td>\n",
       "      <td>58222.0</td>\n",
       "      <td>6469.0</td>\n",
       "      <td>2.391855</td>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.992124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>64678.0</td>\n",
       "      <td>169.665507</td>\n",
       "      <td>0.993481</td>\n",
       "      <td>0.996062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FB</td>\n",
       "      <td>59093.0</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>930.212116</td>\n",
       "      <td>0.973615</td>\n",
       "      <td>0.980389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IF</td>\n",
       "      <td>58222.0</td>\n",
       "      <td>6469.0</td>\n",
       "      <td>7.078562</td>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.992124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HBOS</td>\n",
       "      <td>58222.0</td>\n",
       "      <td>6469.0</td>\n",
       "      <td>2.154905</td>\n",
       "      <td>0.988357</td>\n",
       "      <td>0.997285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LOF</td>\n",
       "      <td>58903.0</td>\n",
       "      <td>5788.0</td>\n",
       "      <td>90.039149</td>\n",
       "      <td>0.975098</td>\n",
       "      <td>0.984264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detector  Outliers  Inliers    Time (s)        F1   ROC_AUC\n",
       "0     None       NaN      NaN         NaN  0.992208  0.997332\n",
       "1    OCSVM   32355.0  32336.0  536.920890  0.896797  0.990901\n",
       "2     ABOD   58034.0   6657.0  112.969116  0.986945  0.992124\n",
       "3    CBLOF   58222.0   6469.0    2.391855  0.986945  0.992124\n",
       "4   DBSCAN      13.0  64678.0  169.665507  0.993481  0.996062\n",
       "5       FB   59093.0   5598.0  930.212116  0.973615  0.980389\n",
       "6       IF   58222.0   6469.0    7.078562  0.986945  0.992124\n",
       "7     HBOS   58222.0   6469.0    2.154905  0.988357  0.997285\n",
       "8      LOF   58903.0   5788.0   90.039149  0.975098  0.984264"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db458622ca08d8b91a8cba06818a45d46a8eaf2221b27a9be390a863a9501f34"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('py_36': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
